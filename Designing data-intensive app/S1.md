
 <div style="
     direction: rtl;
       text-align: justify;
         font-family: 'Vazirmatn', Tahoma, sans-serif;
           font-size: 16px;
             line-height: 2;
               color: #222;
                 background-color: #fdfdfd;
                   padding: 20px;
                     border-radius: 12px;
                       border: 1px solid #ddd;
                         text-align-last: right;
                           unicode-bidi: plaintext;
                           ">     

# فصل اول

**اینترنت آنقدر خوب ساخته شده که اغلب مردم آن را همچون یک منبع طبیعی — نظیر اقیانوس آرام — می‌پندارند تا ساخته‌ای دست بشر. آخرین باری که فناوری در چنین مقیاسی تا این اندازه بی‌نقص عمل کرد، کی بود؟**
— آلن کی، در مصاحبه با مجله Dr Dobb’s Journal (۲۰۱۲)

امروزه بسیاری از برنامه‌ها بیشتر *داده-محور* هستند تا *محاسبه-محور*. توان پردازشی خام (CPU power) به ندرت محدودیت اصلی برای این برنامه‌هاست — مشکلات بزرگ‌تر معمولاً شامل **حجم داده‌ها، پیچیدگی داده‌ها، و سرعت تغییر آن‌ها** می‌شوند.

یک برنامه داده-محور معمولاً از اجزای استانداردی ساخته می‌شود که عملکردهای مورد نیاز معمول را فراهم می‌کنند. برای مثال، بسیاری از برنامه‌ها به موارد زیر نیاز دارند:

* ذخیره‌سازی داده به‌گونه‌ای که خود برنامه یا برنامه‌ای دیگر بتواند در آینده به آن دسترسی یابد (**پایگاه داده‌ها** *databases*)
* به خاطر سپردن نتیجه‌ی یک عملیات پرهزینه برای تسریع در خواندن‌ها (**حافظه‌های نهان** *caches*)
* امکان جستجو در داده‌ها بر اساس کلمات کلیدی یا فیلتر کردن آن به روش‌های گوناگون (**شاخص‌های جستجو** *search indexes*)
* ارسال پیام به فرآیندی دیگر برای پردازش غیربلافاصله (**پردازش جریانی** *stream processing*)
* پردازش حجم زیادی از داده‌های جمع‌آوری‌شده به صورت دوره‌ای (**پردازش دسته‌ای** *batch processing*)

اگر این‌ها بیش از حد بدیهی به نظر می‌رسند، دلیلش این است که این سیستم‌های داده چنان انتزاع‌های موفقی هستند که ما آن‌ها را دائماً و بدون تفکر زیاد استفاده می‌کنیم. هنگام ساخت یک برنامه، بیشتر مهندسان حتی تصور هم نمی‌کنند که بخواهند یک موتور ذخیره‌سازی داده‌ی جدید را از ابتدا بنویسند، زیرا پایگاه‌های داده برای این کار ابزار کاملاً مناسبی هستند.

اما واقعیت به این سادگی نیست. پایگاه‌های داده گوناگونی با ویژگی‌های متفاوت وجود دارند، چرا که برنامه‌های مختلف نیازهای متفاوتی دارند. رویکردهای متنوعی برای caching وجود دارد، چندین راه برای ساخت شاخص‌های جستجو وجود دارد و به همین ترتیب در سایر حوزه‌ها نیز تنوع دیده می‌شود. هنگام ساخت یک برنامه، همچنان باید تشخیص دهیم کدام ابزار و کدام رویکرد برای وظیفه‌ی موجود مناسب‌تر است. و گاه ترکیب ابزارها دشوار می‌شود زمانی که لازم است کاری انجام دهیم که هیچ ابزار منفردی به‌تنهایی قادر به انجام آن نیست.

این کتاب سفری است در دل اصول و واقعیت‌های سیستم‌های داده و چگونگی به‌کارگیری آن‌ها در ساخت برنامه‌های داده-محور. ما بررسی خواهیم کرد که ابزارهای مختلف چه نقاط مشترکی دارند، چه چیز آن‌ها را متمایز می‌کند، و چگونه به ویژگی‌های خاص خود دست می‌یابند.

در این فصل، با بررسی اصول ابتدایی آنچه می‌خواهیم به آن دست یابیم آغاز خواهیم کرد: **سیستم‌های داده قابل‌اطمینان، مقیاس‌پذیر و قابل‌نگهداری**. ما روشن خواهیم کرد که این مفاهیم به چه معنا هستند، برخی شیوه‌های تفکر درباره‌ی آن‌ها را مرور می‌کنیم، و مقدماتی را که برای فصول بعدی نیاز داریم، بیان خواهیم کرد. در فصل‌های آتی، به صورت لایه‌به‌لایه به بررسی تصمیمات طراحی مختلفی می‌پردازیم که هنگام کار روی یک برنامه داده‌-محور باید به آن‌ها توجه شود.

---

## تفکر درباره سیستم‌های داده

ما معمولاً به پایگاه‌های داده، صف‌ها (queues)، حافظه‌های نهان (caches) و... به عنوان دسته‌های بسیار متفاوتی از ابزارها می‌نگریم. اگرچه پایگاه داده و صف پیام در ظاهر شباهت‌هایی دارند — هر دو برای مدتی داده را نگه می‌دارند — اما الگوهای دسترسی آن‌ها بسیار متفاوت است؛ که این به معنای ویژگی‌های عملکردی متفاوت و در نتیجه پیاده‌سازی‌های کاملاً متفاوت است.

پس چرا باید همه‌ی آن‌ها را تحت عنوانی کلی مانند **سیستم‌های داده (data systems)** دسته‌بندی کنیم؟

در سال‌های اخیر، ابزارهای جدید بسیاری برای ذخیره‌سازی و پردازش داده‌ها به وجود آمده‌اند. این ابزارها برای موارد کاربردی (use cases) متنوعی بهینه‌سازی شده‌اند و دیگر به راحتی در دسته‌بندی‌های سنتی نمی‌گنجند \[1]. برای مثال، برخی مخازن داده (datastores) نیز به عنوان صف پیام مورد استفاده قرار می‌گیرند (نظیر **Redis**)، و برخی صف‌های پیام، تضمین‌های پایداری مشابه پایگاه داده را ارائه می‌دهند (مانند **Apache Kafka**). مرزهای میان این دسته‌ها به تدریج در حال کمرنگ شدن است.

دوم اینکه بسیاری از برنامه‌ها امروزه نیازهایی به شدت سخت‌گیرانه یا گسترده دارند که یک ابزار منفرد دیگر نمی‌تواند همه‌ی نیازهای پردازش و ذخیره‌سازی داده‌ی آن‌ها را به تنهایی پوشش دهد. در عوض، کار به وظایفی شکسته می‌شود که هر کدام را بتوان به شکلی کارآمد با یک ابزار خاص انجام داد و این ابزارهای مختلف با کد برنامه به یکدیگر متصل می‌شوند.

برای مثال، اگر شما یک لایه cache که توسط برنامه مدیریت می‌شود (با استفاده از **Memcached** یا مشابه آن) یا یک سرور جستجوی متنی کامل (full-text search server) مانند **Elasticsearch** یا **Solr** مجزا از پایگاه داده اصلی دارید، معمولاً وظیفه‌ی همگام نگه‌داشتن آن cacheها و indexها با پایگاه داده‌ی اصلی، بر عهده کد برنامه است.
شکل ۱-۱ تصویری اجمالی از چنین معماری ارائه می‌دهد (در فصل‌های بعدی جزئیات بیشتری بررسی خواهیم کرد).

---

![](./pic/s1/fig%201-1.png)

**شکل ۱-۱. معماری ممکن برای یک سیستم داده که چندین مؤلفه را با هم ترکیب می‌کند.**

---

هنگامی که چندین ابزار را برای ارائه‌ی یک سرویس با هم ترکیب می‌کنید، رابط سرویس یا **رابط برنامه‌نویسی کاربردی (API)** معمولاً جزئیات پیاده‌سازی را از دید کاربران مخفی می‌کند. در این نقطه، شما عملاً یک **سیستم داده‌ی خاص منظوره** را از مؤلفه‌های عمومی‌تر ساخته‌اید. این سیستم مرکب ممکن است تضمین‌هایی ارائه دهد؛ مثلاً اینکه cache به درستی هنگام نوشتن داده، **باطل (invalidate)** یا به‌روزرسانی شود تا کاربران خارجی نتایج سازگار و منطبق مشاهده کنند.
شما اکنون نه تنها یک برنامه‌نویس، بلکه **طراح سیستم داده** نیز هستید.

زمانی که یک سیستم داده یا سرویس طراحی می‌کنید، پرسش‌های چالش‌برانگیز بسیاری مطرح می‌شود:

* چگونه تضمین می‌کنید که داده حتی در زمان بروز خطاهای داخلی، همچنان صحیح و کامل باقی بماند؟
* چگونه به کاربران خود، حتی در زمان افت کیفیت برخی اجزای سیستم، عملکردی یکنواخت و خوب ارائه می‌دهید؟
* چگونه مقیاس‌پذیری سیستم را برای پاسخ به افزایش بار فراهم می‌کنید؟
* API مناسب برای این سرویس چگونه باید باشد؟

بسیاری از عوامل می‌توانند بر طراحی یک سیستم داده تأثیر بگذارند، از جمله:

* مهارت‌ها و تجربیات افرادی که درگیر پروژه هستند،
* وابستگی به سامانه‌های قدیمی (legacy systems)،
* جدول زمانی تحویل پروژه،
* سطح پذیرش ریسک سازمان در انواع مختلف خطرات،
* محدودیت‌های نظارتی (regulatory constraints)، و...

این عوامل کاملاً وابسته به شرایط خاص هر پروژه هستند.

---

در این کتاب، ما بر روی سه دغدغه تمرکز می‌کنیم که در بیشتر سامانه‌های نرم‌افزاری اهمیت دارند:

### قابلیت اطمینان (Reliability)

سامانه باید حتی در مواجهه با شرایط نامطلوب (مانند خرابی سخت‌افزاری یا نرم‌افزاری، و حتی خطای انسانی) همچنان به درستی کار کند (یعنی عملکرد صحیح را در سطح مطلوب عملکرد ارائه دهد).
به بخش «قابلیت اطمینان» در صفحه ۶ مراجعه کنید.

### مقیاس‌پذیری (Scalability)

با رشد سامانه (از نظر حجم داده، حجم ترافیک، یا پیچیدگی)، باید راهکارهای معقولی برای مدیریت این رشد وجود داشته باشد.
به بخش «مقیاس‌پذیری» در صفحه ۱۰ مراجعه کنید.

### قابلیت نگهداری (Maintainability)

در گذر زمان، افراد مختلفی بر روی سامانه کار خواهند کرد (از جمله مهندسان و تیم‌های عملیاتی، چه برای حفظ رفتار فعلی و چه برای تطبیق سامانه با کاربردهای جدید)، و همه‌ی آن‌ها باید بتوانند به شکل مؤثر و کارآمد روی آن کار کنند.
به بخش «قابلیت نگهداری» در صفحه ۱۸ مراجعه کنید.

این واژه‌ها اغلب به کار می‌روند بدون آنکه درک روشنی از معنای واقعی آن‌ها وجود داشته باشد. به‌منظور مهندسی دقیق و آگاهانه، در ادامه‌ی این فصل روش‌هایی برای تفکر درباره‌ی **قابلیت اطمینان، مقیاس‌پذیری و قابلیت نگهداری** را بررسی خواهیم کرد. سپس در فصل‌های بعدی به بررسی تکنیک‌ها، معماری‌ها و الگوریتم‌های مختلفی می‌پردازیم که برای دستیابی به این اهداف به کار می‌روند.


---

## قابلیت اطمینان (Reliability)

همه‌ی ما به‌طور شهودی می‌دانیم که منظور از چیزی که قابل اطمینان یا غیرقابل اطمینان است چیست. برای نرم‌افزار، انتظارات معمول شامل موارد زیر است:

* برنامه عملکردی را که کاربر انتظار دارد، انجام می‌دهد.
* می‌تواند اشتباهات کاربر یا استفاده‌ی غیرمنتظره از نرم‌افزار را تحمل کند.
* عملکرد آن برای کاربرد موردنظر، تحت بار و حجم داده‌ی مورد انتظار، به اندازه‌ی کافی خوب است.
* سامانه از هرگونه دسترسی غیرمجاز و سوءاستفاده جلوگیری می‌کند.

اگر همه‌ی این موارد در کنار هم به معنای «عملکرد صحیح» باشند، می‌توان قابلیت اطمینان را به طور تقریبی این‌گونه تعریف کرد: «ادامه دادن به عملکرد صحیح، حتی زمانی که مشکلاتی به وجود می‌آید.»

به این مشکلاتی که ممکن است پیش بیایند، خطا (fault) گفته می‌شود و سامانه‌هایی که وقوع خطا را پیش‌بینی می‌کنند و می‌توانند با آن مقابله کنند، خطا-تحمل (fault-tolerant) یا تاب‌آور (resilient) نامیده می‌شوند. اصطلاح fault-tolerant اندکی گمراه‌کننده است: گویی می‌توان سامانه‌ای ساخت که در برابر همه‌ی انواع خطا مقاوم باشد، که در واقعیت عملی نیست. مثلاً اگر کل سیاره‌ی زمین (و تمام سرورهای روی آن) توسط یک سیاه‌چاله بلعیده شود، تحمل چنین خطایی مستلزم میزبانی وب در فضا خواهد بود — امیدوارم بتوان بودجه‌ی چنین پروژه‌ای را تصویب کرد. بنابراین منطقی است که فقط درباره‌ی تحمل انواع خاصی از خطاها صحبت کرد.

توجه داشته باشید که خطا (fault) با شکست (failure) یکسان نیست. خطا معمولاً به انحراف یکی از مؤلفه‌های سامانه از مشخصاتش گفته می‌شود؛ در حالی که شکست زمانی رخ می‌دهد که سامانه به‌طور کلی دیگر نتواند خدمت مورد انتظار را به کاربر ارائه دهد. کاهش احتمال وقوع خطا تا صفر ممکن نیست؛ بنابراین معمولاً بهتر است سازوکارهای تحمل خطا را طراحی کرد که جلوی تبدیل خطا به شکست را بگیرند. در این کتاب، چندین تکنیک برای ساخت سامانه‌های قابل‌اطمینان از اجزای غیرقابل‌اطمینان بررسی می‌شود.

به شکلی متناقض، در سامانه‌های خطا-تحمل، گاهی منطقی است که عمداً نرخ بروز خطا را افزایش داد — مثلاً با کشتن تصادفی برخی فرآیندها بدون هشدار قبلی. بسیاری از اشکالات بحرانی در واقع ناشی از مدیریت ضعیف خطاها هستند؛ با القای عمدی خطاها، می‌توان سازوکارهای تحمل خطا را به طور مستمر به آزمون گذاشت و تمرین داد که این امر باعث افزایش اطمینان از عملکرد صحیح آن‌ها در زمان بروز خطاهای طبیعی می‌شود. Chaos Monkey از شرکت نتفلیکس نمونه‌ای از این رویکرد است.

اگرچه معمولاً تحمل خطا را به پیشگیری از خطا ترجیح می‌دهیم، اما مواردی هم وجود دارد که پیشگیری بهتر از درمان است (مثلاً چون درمانی وجود ندارد). برای مثال در مسائل امنیتی: اگر یک مهاجم به سامانه نفوذ کند و به داده‌های حساس دسترسی یابد، این واقعه قابل برگشت نیست. با این حال، این کتاب عمدتاً به انواعی از خطاها می‌پردازد که می‌توان آن‌ها را درمان کرد، همان‌طور که در بخش‌های بعدی شرح داده خواهد شد.

---

## خطاهای سخت‌افزاری (Hardware Faults)

وقتی به دلایل شکست سامانه فکر می‌کنیم، خطاهای سخت‌افزاری به سرعت به ذهن می‌آیند.
دیسک‌های سخت خراب می‌شوند، حافظه‌ی RAM دچار نقص می‌شود، شبکه‌ی برق قطع می‌شود، کسی به اشتباه کابل شبکه‌ی اشتباهی را جدا می‌کند.
هر کسی که در مراکز داده‌ی بزرگ کار کرده باشد می‌تواند گواهی دهد که این اتفاقات زمانی که تعداد زیادی ماشین دارید، به‌طور مداوم رخ می‌دهد.

گزارش شده که دیسک‌های سخت دارای میانگین زمان تا خرابی (MTTF: Mean Time To Failure) حدود ۱۰ تا ۵۰ سال هستند. بنابراین، در یک خوشه‌ی ذخیره‌سازی با ۱۰٬۰۰۰ دیسک، به طور میانگین می‌توان انتظار داشت که هر روز یک دیسک از کار بیفتد.

اولین واکنش ما معمولاً افزودن افزونگی (redundancy) به اجزای سخت‌افزاری منفرد است تا نرخ شکست کلی سامانه کاهش یابد. دیسک‌ها ممکن است در آرایش RAID پیکربندی شوند، سرورها ممکن است منبع تغذیه‌ی دوگانه و پردازنده‌های قابل تعویض در حال کار (hot-swappable CPUs) داشته باشند، و مراکز داده ممکن است مجهز به باتری و ژنراتورهای دیزل برای تأمین برق پشتیبان باشند.
وقتی یک مؤلفه خراب می‌شود، مؤلفه‌ی افزونه می‌تواند جای آن را بگیرد تا مؤلفه‌ی خراب تعویض شود. این رویکرد نمی‌تواند به‌طور کامل مانع تبدیل مشکلات سخت‌افزاری به شکست شود، اما به خوبی شناخته شده است و می‌تواند باعث شود یک ماشین سال‌ها بدون وقفه کار کند.

تا همین اواخر، افزونگی سخت‌افزاری برای بیشتر برنامه‌ها کافی بود، چرا که خرابی کامل یک ماشین منفرد را نسبتاً نادر می‌ساخت.
تا زمانی که بتوان نسخه‌ی پشتیبان را به سرعت روی یک ماشین جدید بازیابی کرد، قطعی در صورت خرابی برای اغلب برنامه‌ها فاجعه‌بار محسوب نمی‌شود.
بنابراین، افزونگی در سطح چندین ماشین تنها برای تعداد محدودی از برنامه‌ها که به در دسترس بودن بالا (high availability) نیاز حیاتی داشتند، الزامی بود.

اما با افزایش حجم داده‌ها و نیازهای محاسباتی برنامه‌ها، بسیاری از برنامه‌ها شروع به استفاده از تعداد بیشتری ماشین کرده‌اند که متناسباً نرخ بروز خطاهای سخت‌افزاری را افزایش می‌دهد.
علاوه بر این، در برخی پلتفرم‌های ابری مانند Amazon Web Services (AWS) امری نسبتاً معمول است که نمونه‌های ماشین مجازی بدون هشدار در دسترس نباشند، چرا که این پلتفرم‌ها به گونه‌ای طراحی شده‌اند که انعطاف‌پذیری و مقیاس‌پذیری را بر قابلیت اطمینان یک ماشین منفرد ترجیح می‌دهند.

از این رو، گرایشی به سمت سامانه‌هایی به وجود آمده است که می‌توانند از دست رفتن کامل یک ماشین را تحمل کنند، با استفاده از تکنیک‌های تحمل خطای نرم‌افزاری، به جای — یا علاوه بر — افزونگی سخت‌افزاری.
چنین سامانه‌هایی همچنین مزایای عملیاتی دارند: یک سامانه‌ی تک‌سروری در صورت نیاز به راه‌اندازی مجدد (مثلاً برای اعمال وصله‌های امنیتی سیستم عامل) نیازمند قطع زمان‌بندی‌شده‌ی سرویس است، در حالی که سامانه‌ای که می‌تواند خرابی ماشین را تحمل کند، می‌تواند به صورت نوبتی (rolling upgrade) وصله شود، بدون آنکه کل سامانه دچار قطعی شود (به فصل ۴ مراجعه شود).

---

## خطاهای نرم‌افزاری (Software Errors)

ما معمولاً خطاهای سخت‌افزاری را تصادفی و مستقل از یکدیگر تصور می‌کنیم: خراب شدن دیسک یک ماشین به این معنا نیست که دیسک ماشین دیگری نیز خراب خواهد شد.
ممکن است همبستگی‌های ضعیفی وجود داشته باشد (برای مثال به دلیل یک علت مشترک، مانند دمای رک سرور)، اما به طور کلی بعید است که تعداد زیادی از مؤلفه‌های سخت‌افزاری به‌طور همزمان خراب شوند.

دسته‌ی دیگری از خطاها، **خطاهای سیستماتیک (systematic errors)** در سامانه هستند.
چنین خطاهایی پیش‌بینی‌ناپذیرترند و چون در میان گره‌ها همبسته‌اند، معمولاً شکست‌های سامانه‌ای بیشتری نسبت به خطاهای سخت‌افزاری مستقل ایجاد می‌کنند.
نمونه‌هایی از این خطاها عبارت‌اند از:

* یک باگ نرم‌افزاری که باعث می‌شود همه‌ی نمونه‌های سرور برنامه در مواجهه با یک ورودی بد خاص، سقوط (crash) کنند.
  برای مثال، در ۳۰ ژوئن ۲۰۱۲ به‌دلیل اضافه شدن یک ثانیه کبیسه (leap second)، بسیاری از برنامه‌ها به دلیل باگی در کرنل لینوکس به‌طور همزمان دچار قفل شدند.

* یک فرآیند کنترل‌نشده که منابع مشترکی مانند زمان CPU، حافظه، فضای دیسک یا پهنای باند شبکه را به طور کامل مصرف می‌کند.

* یک سرویس وابسته که کند می‌شود، بی‌پاسخ می‌شود یا پاسخ‌های معیوب بازمی‌گرداند.

* شکست‌های زنجیره‌ای (cascading failures)، جایی که یک خطای کوچک در یک مؤلفه، باعث بروز خطا در مؤلفه‌ی دیگری می‌شود و به نوبه‌ی خود به خطاهای بیشتری منجر می‌شود.

باگ‌هایی که این گونه خطاهای نرم‌افزاری را ایجاد می‌کنند اغلب برای مدت طولانی خاموش باقی می‌مانند تا زمانی که توسط مجموعه‌ی غیرمعمولی از شرایط فعال شوند.
در چنین شرایطی، آشکار می‌شود که نرم‌افزار فرضی درباره‌ی محیط خود داشته که معمولاً درست بوده اما به دلایلی دیگر آن فرض صحیح نیست.

راه حل سریع و ساده‌ای برای مشکل خطاهای سیستماتیک نرم‌افزار وجود ندارد.
بسیاری از اقدامات کوچک می‌توانند کمک کنند:
تفکر دقیق درباره‌ی فرضیات و تعاملات در سامانه؛
آزمایش‌های دقیق؛
ایزوله‌سازی فرآیندها؛
امکان دادن به فرآیندها برای سقوط و راه‌اندازی مجدد؛
اندازه‌گیری، پایش و تحلیل رفتار سامانه در محیط عملیاتی.
اگر از سامانه انتظار می‌رود که تضمینی ارائه دهد (برای مثال در یک صف پیام، تعداد پیام‌های ورودی برابر با تعداد پیام‌های خروجی باشد)، می‌تواند به طور مستمر در حین اجرا خود را بررسی کند و در صورت کشف اختلاف، هشدار دهد.

---

## خطاهای انسانی (Human Errors)

انسان‌ها سامانه‌های نرم‌افزاری را طراحی و پیاده‌سازی می‌کنند و اپراتورهایی که این سامانه‌ها را در حال اجرا نگه می‌دارند نیز انسان هستند. حتی زمانی که نیت بهترین باشد، انسان‌ها به‌طور شناخته‌شده‌ای غیرقابل‌اطمینان‌اند.
برای مثال، یک مطالعه روی سرویس‌های اینترنتی بزرگ نشان داد که خطاهای پیکربندی توسط اپراتورها علت اصلی قطع سرویس بوده است، در حالی که خطاهای سخت‌افزاری (سرورها یا شبکه) تنها در ۱۰ تا ۲۵ درصد از قطعی‌ها نقش داشته‌اند.

چگونه می‌توانیم سامانه‌های خود را حتی با وجود انسان‌های غیرقابل‌اطمینان قابل‌اطمینان نگه داریم؟
بهترین سامانه‌ها چندین رویکرد را ترکیب می‌کنند:

* سامانه‌ها را به گونه‌ای طراحی کنیم که فرصت‌های خطا به حداقل برسد.
  برای مثال، انتزاع‌های خوب طراحی‌شده، APIها و رابط‌های مدیریتی (admin interfaces) انجام «کار صحیح» را آسان و انجام «کار اشتباه» را دشوار می‌کنند.
  با این حال، اگر این رابط‌ها بیش از حد محدودکننده باشند، افراد آن‌ها را دور می‌زنند و مزیت‌شان را از بین می‌برند؛ بنابراین رسیدن به تعادل مناسب در این زمینه دشوار است.

* بخش‌هایی که افراد بیشترین اشتباهات را مرتکب می‌شوند از بخش‌هایی که می‌توانند منجر به شکست شوند جدا کنیم.
  به‌طور خاص، محیط‌های آزمایشی غیرتولیدی (sandbox) با امکانات کامل فراهم کنیم که در آن افراد بتوانند با داده‌های واقعی به طور ایمن آزمایش و تجربه کنند بدون آنکه کاربران واقعی تحت تأثیر قرار گیرند.

* آزمایش‌های کامل در تمام سطوح انجام دهیم؛ از آزمون‌های واحد (unit tests) تا آزمون‌های یکپارچه‌سازی کل سامانه و آزمایش‌های دستی.
  آزمون‌های خودکار به‌طور گسترده استفاده می‌شوند، به‌خوبی شناخته شده‌اند و به‌ویژه برای پوشش سناریوهای گوشه‌ای (corner cases) که به ندرت در عملیات عادی رخ می‌دهند بسیار ارزشمندند.

* امکان بازیابی سریع و آسان از خطاهای انسانی فراهم کنیم تا در صورت شکست، تأثیر آن به حداقل برسد.
  برای مثال، بازگرداندن سریع تغییرات پیکربندی، انتشار تدریجی کد جدید (تا باگ‌های غیرمنتظره تنها درصد کمی از کاربران را تحت تأثیر قرار دهند)، و ارائه ابزارهایی برای بازمحاسبه داده‌ها (در صورتی که محاسبه قبلی اشتباه بوده باشد).

* پایش دقیق و شفاف پیاده‌سازی کنیم، نظیر سنجه‌های عملکرد (performance metrics) و نرخ خطاها.
  در سایر رشته‌های مهندسی، این کار به عنوان «تله‌متری» (telemetry) شناخته می‌شود.
  (زمانی که یک راکت از زمین بلند می‌شود، تله‌متری برای پیگیری وقایع و درک شکست‌ها حیاتی است.)
  پایش می‌تواند علائم هشدار اولیه را نشان دهد و امکان بررسی نقض شدن هرگونه فرض یا محدودیتی را فراهم آورد.
  وقتی مشکلی رخ می‌دهد، سنجه‌ها برای عیب‌یابی مسئله بسیار ارزشمندند.

* پیاده‌سازی شیوه‌های مدیریتی خوب و آموزش مناسب — جنبه‌ای پیچیده و مهم که خارج از حیطه‌ی این کتاب است.

---

## قابلیت اطمینان چقدر اهمیت دارد؟ (How Important Is Reliability?)

قابلیت اطمینان تنها برای نیروگاه‌های هسته‌ای و نرم‌افزارهای کنترل ترافیک هوایی اهمیت ندارد — حتی برنامه‌های عادی‌تر نیز انتظار می‌رود به شکل قابل اطمینان کار کنند.
باگ‌ها در برنامه‌های تجاری منجر به کاهش بهره‌وری می‌شوند (و در صورتی که گزارش‌های عددی اشتباه باشند، خطرات قانونی نیز در پی دارند) و قطعی در سایت‌های تجارت الکترونیک می‌تواند هزینه‌های هنگفتی به صورت از دست رفتن درآمد و آسیب به شهرت ایجاد کند.

حتی در برنامه‌های «غیر بحرانی» نیز در قبال کاربران خود مسئولیت داریم.
تصور کنید پدر یا مادری که تمام عکس‌ها و ویدیوهای فرزندان خود را در برنامه‌ی عکس شما ذخیره کرده است.
اگر آن پایگاه داده به طور ناگهانی خراب شود، چه احساسی خواهند داشت؟
آیا می‌دانند چگونه می‌توانند آن را از نسخه‌ی پشتیبان بازیابی کنند؟

البته شرایطی وجود دارد که ممکن است تصمیم بگیریم به‌منظور کاهش هزینه‌ی توسعه (برای مثال، هنگام توسعه‌ی یک نمونه‌ی اولیه برای بازاری اثبات‌نشده) یا هزینه‌ی عملیاتی (برای مثال، در خدمتی با حاشیه سود بسیار کم) از قابلیت اطمینان بکاهیم — اما باید کاملاً آگاه باشیم که چه زمانی داریم از کیفیت چشم‌پوشی می‌کنیم.

---

## مقیاس‌پذیری (Scalability)

حتی اگر یک سامانه امروز به شکل قابل‌اعتمادی کار کند، به این معنا نیست که لزوماً در آینده نیز به همین شکل باقی خواهد ماند. یکی از دلایل متداول برای افت عملکرد، افزایش بار است:
شاید سامانه از ۱۰٬۰۰۰ کاربر همزمان به ۱۰۰٬۰۰۰ کاربر همزمان رسیده است، یا از ۱ میلیون به ۱۰ میلیون رشد کرده است.
شاید اکنون حجم بسیار بیشتری از داده را نسبت به قبل پردازش می‌کند.

**مقیاس‌پذیری** اصطلاحی است که برای توصیف توانایی سامانه در مقابله با افزایش بار به کار می‌بریم.
با این حال، باید توجه داشت که این یک برچسب تک‌بعدی نیست که بتوان به سامانه چسباند:
بی‌معناست که بگوییم «سیستم X مقیاس‌پذیر است» یا «سیستم Y مقیاس‌پذیر نیست.»
بحث درباره‌ی مقیاس‌پذیری یعنی پاسخ به پرسش‌هایی نظیر:
«اگر سامانه به شکل خاصی رشد کند، چه گزینه‌هایی برای مدیریت این رشد داریم؟» و
«چگونه می‌توان منابع محاسباتی را برای تحمل بار اضافی اضافه کرد؟»

### توصیف بار (Describing Load)

ابتدا لازم است بار فعلی سامانه را به شکلی خلاصه توصیف کنیم؛ تنها در این صورت می‌توانیم درباره‌ی رشد بحث کنیم (مثلاً: چه اتفاقی می‌افتد اگر بار ما دو برابر شود؟).
بار را می‌توان با چند عدد که به آن‌ها **پارامترهای بار (load parameters)** می‌گوییم، توصیف کرد.
بهترین انتخاب پارامترها بستگی به معماری سامانه دارد: ممکن است درخواست در ثانیه به یک وب‌سرور باشد؛ نسبت خواندن به نوشتن در یک پایگاه داده؛ تعداد کاربران همزمان فعال در یک چت‌روم؛ نرخ اصابت در یک حافظه‌ی نهان (cache hit rate)؛ یا چیزهای دیگر.
شاید میانگین برای شما مهم باشد، یا شاید گلوگاه شما تحت تأثیر تعداد کمی از موارد شدید (worst cases) باشد.

برای ملموس‌تر کردن این ایده، اجازه دهید توییتر را به عنوان مثال در نظر بگیریم، با استفاده از داده‌هایی که در نوامبر ۲۰۱۲ منتشر شد.
دو عملیات اصلی در توییتر عبارت‌اند از:

**ارسال توییت (Post tweet):**
کاربر می‌تواند پیام جدیدی را برای دنبال‌کنندگان خود منتشر کند (به طور میانگین ۴۶۰۰ درخواست در ثانیه، در اوج بیش از ۱۲٬۰۰۰ درخواست در ثانیه).

**جدول زمانی خانه (Home timeline):**
کاربر می‌تواند توییت‌های ارسال‌شده توسط افرادی که دنبال می‌کند را مشاهده کند (۳۰۰٬۰۰۰ درخواست در ثانیه).

صرفاً مدیریت ۱۲٬۰۰۰ نوشتن در ثانیه (نرخ اوج برای ارسال توییت) نسبتاً آسان است.
اما چالش اصلی مقیاس‌پذیری توییتر ناشی از حجم توییت‌ها نیست، بلکه ناشی از **fan-out** است — هر کاربر افراد زیادی را دنبال می‌کند و توسط افراد زیادی دنبال می‌شود.

به طور کلی دو روش برای پیاده‌سازی این دو عملیات وجود دارد:

1. ارسال یک توییت صرفاً رکورد جدیدی را به مجموعه‌ی جهانی توییت‌ها اضافه می‌کند.
   زمانی که کاربر جدول زمانی خانه‌ی خود را درخواست می‌کند، باید همه‌ی افرادی را که دنبال می‌کند جستجو کرد، تمام توییت‌های آن‌ها را پیدا کرد و آن‌ها را (به ترتیب زمان) ادغام کرد.
   در یک پایگاه داده رابطه‌ای مانند شکل ۱-۲، می‌توان چنین کوئری نوشت:

```sql
SELECT tweets.*, users.* FROM tweets
JOIN users
ON tweets.sender_id = users.id
JOIN follows 
ON follows.followee_id = users.id
WHERE follows.follower_id = current_user
```


2. برای هر کاربر، یک حافظه‌ی نهان (cache) از جدول زمانی خانه‌ی او نگهداری شود — مانند یک صندوق پستی از توییت‌ها برای هر کاربر دریافت‌کننده (به شکل ۱-۳ مراجعه کنید).
   زمانی که یک کاربر توییتی ارسال می‌کند، همه‌ی افرادی را که آن کاربر را دنبال می‌کنند جستجو کرده و توییت جدید را در حافظه‌ی نهان جدول زمانی خانه‌ی هر یک از آن‌ها درج می‌کنیم.
   در این صورت، درخواست خواندن جدول زمانی خانه بسیار ارزان می‌شود، زیرا نتیجه از پیش محاسبه شده است.



![](./pic/s1/fig%201-3%20&1-2.png)
**شکل ۱-۳. خط لوله‌ی داده‌ی توییتر برای تحویل توییت‌ها به دنبال‌کنندگان، همراه با پارامترهای بار مربوط به نوامبر ۲۰۱۲.**

نسخه‌ی اولیه‌ی توییتر از رویکرد اول استفاده می‌کرد، اما سامانه‌ها در برابر بار بالای درخواست‌های جدول زمانی خانه دچار مشکل می‌شدند؛ بنابراین شرکت به رویکرد دوم روی آورد.
این روش بهتر عمل می‌کند، زیرا نرخ متوسط ارسال توییت تقریباً دو مرتبه بزرگی کمتر از نرخ خواندن جدول زمانی خانه است؛ و در این حالت، انجام کار بیشتر هنگام نوشتن و کار کمتر هنگام خواندن، مطلوب‌تر است.

با این حال، نقطه‌ضعف رویکرد دوم این است که ارسال یک توییت اکنون مستلزم کار اضافی فراوانی است.
به‌طور میانگین، هر توییت برای حدود ۷۵ دنبال‌کننده ارسال می‌شود، بنابراین ۴٬۶۰۰ توییت در ثانیه تبدیل به ۳۴۵٬۰۰۰ نوشتن در ثانیه برای حافظه‌های نهان جدول زمانی خانه می‌شود.
اما این میانگین پنهان می‌کند که تعداد دنبال‌کنندگان هر کاربر به شدت متغیر است و برخی کاربران بیش از ۳۰ میلیون دنبال‌کننده دارند.
این یعنی یک توییت ممکن است منجر به بیش از ۳۰ میلیون عملیات نوشتن در حافظه‌های نهان جدول زمانی خانه شود!
انجام این کار در زمان مناسب — توییتر سعی دارد توییت‌ها را ظرف پنج ثانیه به دنبال‌کنندگان تحویل دهد — چالش قابل‌توجهی است.

در مثال توییتر، توزیع تعداد دنبال‌کنندگان هر کاربر (شاید با وزن‌دهی به دفعات توییت‌کردن آن‌ها) یک پارامتر کلیدی بار برای بحث مقیاس‌پذیری محسوب می‌شود، زیرا بار fan-out را تعیین می‌کند.
برنامه‌ی شما ممکن است ویژگی‌های کاملاً متفاوتی داشته باشد، اما می‌توان اصول مشابهی را برای تحلیل بار آن به کار برد.

آخرین نکته در داستان توییتر: اکنون که رویکرد دوم به شکل قابل‌اتکایی پیاده‌سازی شده است، توییتر به سمت یک رویکرد ترکیبی از هر دو حرکت کرده است.
توییت‌های بیشتر کاربران همچنان هنگام ارسال در حافظه‌های نهان جدول زمانی خانه‌ی دنبال‌کنندگان گسترش می‌یابد (fan-out)، اما برای تعداد اندکی از کاربران با دنبال‌کنندگان بسیار زیاد (یعنی افراد مشهور)، این fan-out انجام نمی‌شود.
توییت‌های افراد مشهوری که یک کاربر دنبال می‌کند به‌طور جداگانه فراخوانی شده و هنگام خواندن جدول زمانی خانه با آن ادغام می‌شوند، همانند رویکرد اول.
این رویکرد ترکیبی می‌تواند عملکردی پایدار و خوب ارائه دهد.
به این مثال در فصل ۱۲ بازخواهیم گشت پس از آنکه برخی زمینه‌های فنی بیشتر را پوشش داده باشیم.

---
---

## توصیف عملکرد (Describing Performance)

پس از آنکه بار سامانه خود را توصیف کردید، می‌توانید بررسی کنید که در صورت افزایش بار، چه اتفاقی می‌افتد.
این موضوع را می‌توان از دو منظر بررسی کرد:

* زمانی که یکی از پارامترهای بار را افزایش می‌دهید ولی منابع سامانه (CPU، حافظه، پهنای باند شبکه و...) را ثابت نگه می‌دارید، عملکرد سامانه چگونه تحت تأثیر قرار می‌گیرد؟

* زمانی که یکی از پارامترهای بار را افزایش می‌دهید، برای حفظ عملکرد بدون تغییر، چقدر باید منابع را افزایش دهید؟

برای پاسخ به هر دو پرسش به مقادیر عملکردی نیاز است؛ بنابراین به طور خلاصه به نحوه‌ی توصیف عملکرد یک سامانه می‌پردازیم.

در سامانه‌های پردازش دسته‌ای مانند Hadoop، معمولاً به **توان عملیاتی (throughput)** اهمیت می‌دهیم — یعنی تعداد رکوردهایی که می‌توانیم در ثانیه پردازش کنیم، یا کل زمانی که برای اجرای یک job روی مجموعه‌داده‌ای با اندازه مشخص صرف می‌شود.
در سامانه‌های آنلاین، معمولاً **زمان پاسخ (response time)** اهمیت بیشتری دارد — یعنی مدت زمانی که بین ارسال یک درخواست از سوی کاربر و دریافت پاسخ سپری می‌شود.

### تأخیر و زمان پاسخ (Latency and response time)

اصطلاحات **تأخیر (latency)** و **زمان پاسخ (response time)** اغلب به جای هم به کار می‌روند، اما یکسان نیستند.
**زمان پاسخ** چیزی است که مشتری مشاهده می‌کند: علاوه بر زمان واقعی پردازش درخواست (service time)، شامل تأخیرهای شبکه و صف نیز می‌شود.
**تأخیر** مدت زمانی است که یک درخواست در انتظار پردازش است — یعنی در حالت *latent* قرار دارد و منتظر سرویس‌دهی است.

حتی اگر یک درخواست کاملاً مشابه را بارها و بارها ارسال کنید، در هر بار پاسخ کمی متفاوت دریافت می‌کنید.
در عمل، در سامانه‌ای که انواع مختلفی از درخواست‌ها را مدیریت می‌کند، زمان پاسخ می‌تواند بسیار متغیر باشد.
بنابراین باید زمان پاسخ را نه به عنوان یک عدد منفرد، بلکه به عنوان یک **توزیع از مقادیر قابل اندازه‌گیری** در نظر گرفت.

در شکل ۱-۴، هر میله‌ی خاکستری نمایانگر یک درخواست به سرویس است و ارتفاع آن نشان می‌دهد که آن درخواست چقدر طول کشیده است.
بیشتر درخواست‌ها نسبتاً سریع پاسخ داده می‌شوند، اما گهگاهی درخواست‌هایی مشاهده می‌شود که مدت بسیار بیشتری طول می‌کشد.
شاید درخواست‌های کند ذاتاً سنگین‌تر باشند؛ برای مثال، به این دلیل که داده‌های بیشتری پردازش می‌کنند.
اما حتی در سناریویی که انتظار می‌رود تمام درخواست‌ها زمان یکسانی ببرند، باز هم تغییرات رخ می‌دهد:
تأخیرهای تصادفی می‌تواند ناشی از مواردی مانند: سوئیچ زمینه به یک فرآیند پس‌زمینه؛
از دست رفتن بسته‌ی شبکه و ارسال مجدد توسط TCP؛
مکث در جمع‌آوری زباله (garbage collection pause)؛
خطای صفحه (page fault) که خواندن از دیسک را مجبور می‌کند؛
لرزش مکانیکی در رک سرور؛ و بسیاری علل دیگر باشد.

---
![](./pic/s1/fig%201-4.png)
**شکل ۱-۴. نمایش میانگین و صدک‌ها: زمان‌های پاسخ برای نمونه‌ای از ۱۰۰ درخواست به یک سرویس.**

معمول است که میانگین زمان پاسخ یک سرویس گزارش شود.
(به‌طور دقیق، اصطلاح «میانگین» به هیچ فرمول خاصی اشاره نمی‌کند، اما در عمل معمولاً به میانگین حسابی اشاره دارد: مجموع n مقدار را حساب کرده و بر n تقسیم می‌کنیم.)
با این حال، **میانگین معیار چندان خوبی نیست** اگر بخواهید بدانید زمان پاسخ «نمونه‌ای» از کاربران چقدر است، چون نمی‌گوید چه تعداد کاربر واقعاً آن مقدار تأخیر را تجربه کرده‌اند.

معمولاً استفاده از **صدک‌ها (percentiles)** بهتر است.
اگر فهرست زمان‌های پاسخ را از سریع‌ترین تا کندترین مرتب کنید، میانه (median) نقطه‌ی میانی خواهد بود:
برای مثال، اگر میانه‌ی زمان پاسخ شما ۲۰۰ میلی‌ثانیه باشد، یعنی نیمی از درخواست‌ها کمتر از ۲۰۰ میلی‌ثانیه پاسخ داده می‌شوند و نیمی دیگر بیشتر از آن طول می‌کشند.

این موضوع میانه را به معیاری خوب برای دانستن مدت زمان انتظار «معمولی» کاربران تبدیل می‌کند:
نیمی از درخواست‌ها سریع‌تر از میانه پاسخ می‌گیرند و نیمی دیگر کندتر.
میانه همچنین به عنوان **صدک پنجاهم (50th percentile)** شناخته می‌شود و گاهی به صورت **p50** خلاصه می‌شود.
توجه داشته باشید که میانه به یک درخواست منفرد اشاره دارد؛
اگر کاربر چندین درخواست انجام دهد (در طول یک جلسه یا به خاطر بارگذاری چند منبع در یک صفحه)، احتمال اینکه حداقل یکی از آن‌ها کندتر از میانه باشد، بسیار بیشتر از ۵۰٪ خواهد بود.

برای درک اینکه بدترین نمونه‌های کندی چقدر شدید هستند، می‌توانید به صدک‌های بالاتر نگاه کنید:
صدک ۹۵، ۹۹ و ۹۹.۹ معمول هستند (به صورت **p95**، **p99** و **p999** نمایش داده می‌شوند).
این مقادیر آستانه‌های زمانی پاسخ هستند که به ترتیب ۹۵٪، ۹۹٪ و ۹۹.۹٪ از درخواست‌ها سریع‌تر از آن مقدار پاسخ می‌گیرند.
برای مثال، اگر صدک ۹۵ام زمان پاسخ ۱.۵ ثانیه باشد، یعنی از هر ۱۰۰ درخواست، ۹۵ درخواست کمتر از ۱.۵ ثانیه و ۵ درخواست ۱.۵ ثانیه یا بیشتر طول می‌کشد.
این موضوع در شکل ۱-۴ نشان داده شده است.

**صدک‌های بالای زمان پاسخ، که به آن‌ها تأخیر دم (tail latency) نیز گفته می‌شود، اهمیت بالایی دارند، زیرا مستقیماً بر تجربه‌ی کاربر از سرویس تأثیر می‌گذارند.**
برای مثال، آمازون نیازمندی‌های زمانی پاسخ سرویس‌های داخلی خود را بر اساس صدک ۹۹.۹ام تعریف می‌کند، هرچند که تنها ۱ درخواست در هر ۱٬۰۰۰ درخواست را شامل می‌شود.
دلیل این کار آن است که مشتریانی که درخواست‌های کندتری دارند، اغلب همان‌هایی هستند که بیشترین داده را در حساب خود دارند، چون خریدهای زیادی انجام داده‌اند — یعنی باارزش‌ترین مشتریان هستند.
نگه داشتن رضایت این مشتریان با تضمین سرعت بالای وب‌سایت برای آن‌ها اهمیت دارد:
آمازون همچنین مشاهده کرده که افزایش ۱۰۰ میلی‌ثانیه‌ای در زمان پاسخ، فروش را ۱٪ کاهش می‌دهد، و دیگران گزارش داده‌اند که کاهش سرعت به اندازه‌ی ۱ ثانیه، شاخص رضایت مشتری را ۱۶٪ کاهش می‌دهد.

---

از سوی دیگر، بهینه‌سازی **صدک ۹۹.۹۹ام** (کندترین ۱ درخواست در هر ۱۰٬۰۰۰ درخواست) برای اهداف آمازون بیش از حد پرهزینه و با فایده‌ی ناکافی در نظر گرفته شده است.
کاهش زمان پاسخ در صدک‌های بسیار بالا دشوار است زیرا به آسانی تحت تأثیر رویدادهای تصادفی خارج از کنترل شما قرار می‌گیرد و منافع آن با افزایش هزینه به تدریج کاهش می‌یابد.

برای مثال، صدک‌ها اغلب در **اهداف سطح سرویس (SLO: Service Level Objectives)** و **توافقنامه‌های سطح سرویس (SLA: Service Level Agreements)** به کار می‌روند — قراردادهایی که عملکرد و در دسترس بودن مورد انتظار یک سرویس را تعریف می‌کنند.
یک SLA ممکن است بیان کند که سرویس در صورتی «فعال» محسوب می‌شود که میانه‌ی زمان پاسخ کمتر از ۲۰۰ میلی‌ثانیه و صدک ۹۹ام کمتر از ۱ ثانیه باشد (اگر زمان پاسخ طولانی‌تر شود، در عمل می‌توان آن را قطع‌شده در نظر گرفت)، و سرویس باید دست‌کم ۹۹.۹٪ از زمان در دسترس باشد.
این معیارها انتظارات را برای مشتریان سرویس مشخص می‌کنند و به مشتریان اجازه می‌دهند در صورت عدم تحقق SLA درخواست بازپرداخت کنند.

**تأخیرهای صف (Queueing delays)** اغلب بخش بزرگی از زمان پاسخ در صدک‌های بالا را تشکیل می‌دهند.
چون یک سرور فقط می‌تواند تعداد محدودی کار را به طور همزمان پردازش کند (برای مثال محدود به تعداد هسته‌های CPU)، تنها چند درخواست کند کافی است تا پردازش درخواست‌های بعدی را نیز معطل کند — اثری که گاهی به آن **انسداد ابتدای صف (head-of-line blocking)** گفته می‌شود.
حتی اگر درخواست‌های بعدی روی سرور به سرعت پردازش شوند، مشتری به دلیل انتظار برای تکمیل درخواست قبلی، زمان پاسخ کلی کندی را تجربه خواهد کرد.
به دلیل این اثر، مهم است که زمان‌های پاسخ را در سمت مشتری اندازه‌گیری کنیم.

زمانی که برای آزمایش مقیاس‌پذیری سامانه به طور مصنوعی بار تولید می‌کنیم، **کلاینت تولیدکننده‌ی بار باید به شکل مستقل و پیوسته درخواست ارسال کند، بدون اینکه منتظر تکمیل درخواست قبلی بماند.**
اگر کلاینت منتظر بماند تا درخواست قبلی تمام شود، این رفتار موجب می‌شود طول صف‌ها در آزمایش به شکل مصنوعی کوتاه‌تر از شرایط واقعی باشد که در نهایت اندازه‌گیری‌ها را منحرف می‌کند.

---
---

## صدک‌ها در عمل (Percentiles in Practice)

**صدک‌های بالا به‌ویژه در سرویس‌های پشتیبان (backend)** که چندین بار در فرآیند پاسخ به یک درخواست کاربر نهایی فراخوانی می‌شوند اهمیت پیدا می‌کنند.
حتی اگر این فراخوانی‌ها به صورت موازی انجام شوند، درخواست کاربر نهایی باید تا زمانی که کندترین فراخوانی به پایان برسد، منتظر بماند.
فقط یک فراخوانی کند کافی است تا کل درخواست کاربر نهایی کند شود؛ همان‌طور که در شکل ۱-۵ نشان داده شده است.
حتی اگر تنها درصد کمی از فراخوانی‌های پشتیبان کند باشند، هر چه درخواست کاربر به فراخوانی‌های پشتیبان بیشتری وابسته باشد، احتمال وقوع یک فراخوانی کند افزایش می‌یابد و در نتیجه درصد بیشتری از درخواست‌های کاربر نهایی کند می‌شوند.
به این اثر **تقویت تأخیر انتهایی (tail latency amplification)** گفته می‌شود.

اگر می‌خواهید **صدک‌های زمان پاسخ را به داشبوردهای پایش سرویس‌های خود اضافه کنید**، باید بتوانید آن‌ها را به‌طور مستمر و کارآمد محاسبه کنید.
برای مثال، ممکن است بخواهید یک پنجره‌ی لغزان (rolling window) از زمان پاسخ درخواست‌ها در ۱۰ دقیقه‌ی اخیر نگه دارید.
هر دقیقه، میانه و صدک‌های مختلف را روی مقادیر این پنجره محاسبه کرده و این معیارها را روی نمودار رسم کنید.

پیاده‌سازی ساده این است که فهرستی از زمان‌های پاسخ تمام درخواست‌ها در بازه‌ی زمانی نگه دارید و هر دقیقه آن را مرتب (sort) کنید.
اگر این روش برای شما ناکارآمد است، الگوریتم‌هایی وجود دارند که می‌توانند **تقریب مناسبی از صدک‌ها را با هزینه‌ی اندک پردازشی و حافظه‌ای** محاسبه کنند، مانند:

* **forward decay**
* **t-digest**
* **HdrHistogram**

به این نکته توجه کنید که **میانگین‌گیری از صدک‌ها به لحاظ ریاضی بی‌معناست** — برای مثال اگر بخواهید برای کاهش تفکیک زمانی یا تجمیع داده‌ها از چندین ماشین، صدک‌ها را میانگین بگیرید.
روش صحیح برای تجمیع داده‌های زمان پاسخ، **جمع‌کردن هیستوگرام‌ها** است.

---

![](./pic/s1/fig%201-6.png)

**شکل ۱-۵. زمانی که برای پاسخ به یک درخواست به چندین فراخوانی پشتیبان نیاز باشد، فقط یک درخواست پشتیبان کند کافی است تا کل درخواست کاربر نهایی کند شود.**

## رویکردهایی برای مقابله با بار (Approaches for Coping with Load)

اکنون که پارامترهای توصیف بار و معیارهای اندازه‌گیری عملکرد را بررسی کردیم، می‌توانیم بحث جدی در مورد مقیاس‌پذیری را آغاز کنیم:
چگونه می‌توانیم عملکرد خوبی را حتی زمانی که پارامترهای بار افزایش می‌یابد، حفظ کنیم؟

معماری که برای یک سطح بار مناسب است، به احتمال زیاد نمی‌تواند با ۱۰ برابر شدن آن بار کنار بیاید.
اگر روی سرویسی با رشد سریع کار می‌کنید، احتمالاً لازم خواهد بود در هر مرتبه بزرگی افزایش بار (یا حتی بیشتر از آن)، معماری خود را بازنگری کنید.

اغلب بین **مقیاس‌پذیری عمودی (scaling up / vertical scaling)** — یعنی مهاجرت به ماشین قدرتمندتر — و **مقیاس‌پذیری افقی (scaling out / horizontal scaling)** — یعنی توزیع بار روی چندین ماشین کوچک‌تر — تمایز قائل می‌شوند.
توزیع بار روی چندین ماشین همچنین به عنوان **معماری بدون اشتراک (shared-nothing architecture)** شناخته می‌شود.
سامانه‌ای که بتواند روی یک ماشین منفرد اجرا شود معمولاً ساده‌تر است، اما ماشین‌های بسیار قدرتمند می‌توانند بسیار گران باشند؛ بنابراین بارهای بسیار سنگین معمولاً نمی‌توانند از مقیاس‌پذیری افقی اجتناب کنند.
در عمل، معماری‌های خوب معمولاً شامل ترکیبی عمل‌گرایانه از این دو رویکرد هستند:
برای مثال، استفاده از چند ماشین نسبتاً قدرتمند ممکن است همچنان ساده‌تر و ارزان‌تر از تعداد زیادی ماشین مجازی کوچک باشد.

برخی سامانه‌ها **انعطاف‌پذیر (elastic)** هستند، به این معنا که می‌توانند هنگام تشخیص افزایش بار، منابع محاسباتی را به طور خودکار اضافه کنند.
برخی دیگر به صورت دستی مقیاس می‌گیرند (یعنی یک فرد ظرفیت را تحلیل می‌کند و تصمیم می‌گیرد ماشین‌های بیشتری به سامانه اضافه کند).
سامانه‌ی انعطاف‌پذیر می‌تواند برای بارهای غیرقابل پیش‌بینی بسیار مفید باشد، اما سامانه‌های مقیاس‌پذیری دستی ساده‌تر هستند و ممکن است شگفتی‌های عملیاتی کمتری ایجاد کنند.


در حالی که **توزیع سرویس‌های بدون وضعیت (stateless services)** روی چندین ماشین نسبتاً ساده است،
منتقل کردن سیستم‌های داده دارای وضعیت (stateful) از یک گره منفرد به یک محیط توزیع‌شده می‌تواند پیچیدگی‌های فراوانی ایجاد کند.
به همین دلیل، تا مدت‌ها توصیه‌ی رایج این بود که پایگاه داده را روی یک گره منفرد نگه دارید (**مقیاس‌پذیری عمودی**) تا زمانی که هزینه‌ی مقیاس‌پذیری یا نیاز به دسترسی‌پذیری بالا شما را مجبور به توزیع آن کند.

با بهتر شدن ابزارها و انتزاع‌های سیستم‌های توزیع‌شده، این توصیه‌ی رایج ممکن است دست‌کم برای برخی انواع برنامه‌ها تغییر کند.
قابل تصور است که در آینده، سیستم‌های داده‌ی توزیع‌شده حتی برای کاربردهایی که با حجم بالایی از داده یا ترافیک سروکار ندارند، به حالت پیش‌فرض تبدیل شوند.
در ادامه‌ی این کتاب، انواع مختلفی از سیستم‌های داده توزیع‌شده را بررسی می‌کنیم و نه تنها از منظر مقیاس‌پذیری، بلکه از نظر سهولت استفاده و قابلیت نگهداری نیز آن‌ها را مورد بحث قرار می‌دهیم.

معماری سامانه‌هایی که در مقیاس بزرگ فعالیت می‌کنند معمولاً به شدت خاص کاربرد است —
چیزی به نام معماری مقیاس‌پذیر عمومی و جهان‌شمول (که گاه به شوخی *magic scaling sauce* نامیده می‌شود) وجود ندارد.
مشکل ممکن است حجم خواندن‌ها، حجم نوشتن‌ها، حجم داده برای ذخیره‌سازی، پیچیدگی داده‌ها، نیازهای زمان پاسخ، الگوهای دسترسی، یا معمولاً ترکیبی از همه‌ی این‌ها به همراه مسائل بسیار بیشتری باشد.

برای مثال، سامانه‌ای که برای مدیریت ۱۰۰٬۰۰۰ درخواست در ثانیه، هر کدام با اندازه‌ی ۱ کیلوبایت طراحی شده، کاملاً متفاوت از سامانه‌ای است که برای ۳ درخواست در دقیقه، هر کدام به اندازه‌ی ۲ گیگابایت طراحی شده است —
هرچند هر دو سامانه توان عملیاتی داده‌ی (data throughput) مشابهی دارند.

معماری‌ای که برای یک کاربرد خاص به خوبی مقیاس می‌گیرد، بر اساس فرضیاتی درباره‌ی اینکه کدام عملیات‌ها رایج و کدام نادر خواهند بود — یعنی همان پارامترهای بار — ساخته می‌شود.
اگر این فرضیات نادرست از آب درآیند، تلاش مهندسی صرف‌شده برای مقیاس‌پذیری در بهترین حالت هدر رفته و در بدترین حالت نتیجه‌ی معکوس خواهد داد.
در یک استارتاپ اولیه یا محصول اثبات‌نشده، معمولاً **توانایی سریع در تغییر و تکامل ویژگی‌های محصول مهم‌تر از آمادگی برای مقیاس‌پذیری در برابر باری فرضی در آینده** است.

هرچند معماری‌های مقیاس‌پذیر خاص کاربرد هستند،
اما معمولاً از اجزای عمومی و الگوهای آشنایی ساخته می‌شوند.
در این کتاب این اجزا و الگوها را بررسی می‌کنیم.

---

## قابلیت نگهداری (Maintainability)

به‌خوبی شناخته شده است که بخش عمده‌ی هزینه‌ی نرم‌افزار در توسعه‌ی اولیه‌ی آن نیست، بلکه در **نگهداری مداوم** آن قرار دارد شامل رفع باگ‌ها، عملیاتی نگه داشتن سامانه، بررسی شکست‌ها، سازگار کردن آن با پلتفرم‌های جدید، تطبیق برای کاربردهای جدید، بازپرداخت بدهی فنی، و افزودن ویژگی‌های جدید.

با این حال، متأسفانه بسیاری از افرادی که روی سیستم‌های نرم‌افزاری کار می‌کنند، از نگهداری سامانه‌های موسوم به **سامانه‌های میراثی (legacy systems)** بیزارند شاید به این دلیل که مستلزم رفع اشتباهات دیگران است، یا کار با پلتفرم‌هایی است که اکنون منسوخ شده‌اند، یا سامانه‌هایی هستند که مجبور شده‌اند کارهایی را انجام دهند که هرگز برای آن طراحی نشده بودند.
هر سامانه‌ی میراثی به شیوه‌ی خاص خود ناخوشایند است، و بنابراین ارائه‌ی توصیه‌های کلی برای مقابله با آن‌ها دشوار است.

با این حال، می‌توانیم و باید نرم‌افزار را به گونه‌ای طراحی کنیم که دردسرهای نگهداری در آینده به حداقل برسد و از این طریق از تولید نرم‌افزارهای میراثی جدید جلوگیری کنیم.
برای این منظور، به سه اصل طراحی در سامانه‌های نرم‌افزاری توجه ویژه خواهیم کرد:

### قابلیت عملیات (Operability)

ایجاد سهولت برای تیم‌های عملیاتی در جهت نگه داشتن سامانه به‌صورت روان و بی‌وقفه.

### سادگی (Simplicity)

ایجاد سهولت برای مهندسان جدید جهت درک سامانه، از طریق حذف هرچه بیشتر پیچیدگی از سامانه.
(توجه داشته باشید که این موضوع با سادگی رابط کاربری یکسان نیست.)

### قابلیت تحول (Evolvability)

ایجاد سهولت برای مهندسان جهت ایجاد تغییرات در سامانه در آینده،
برای سازگار کردن آن با کاربردهای غیرقابل پیش‌بینی به موازات تغییر نیازمندی‌ها.
همچنین به عنوان **قابلیت توسعه (extensibility)**، **قابلیت تغییر (modifiability)** یا **انعطاف‌پذیری (plasticity)** نیز شناخته می‌شود.

همانند بحث‌های قبلی در مورد قابلیت اطمینان و مقیاس‌پذیری، راه‌حل‌های ساده‌ای برای دستیابی به این اهداف وجود ندارد.
بلکه تلاش خواهیم کرد با ذهنیتی مبتنی بر قابلیت عملیات، سادگی و قابلیت تحول به سامانه‌ها نگاه کنیم.

---

## قابلیت عملیات: آسان کردن زندگی تیم عملیات (Operability: Making Life Easy for Operations)

گفته شده است:
**«عملیات خوب اغلب می‌تواند محدودیت‌های نرم‌افزار بد (یا ناقص) را جبران کند، اما نرم‌افزار خوب نمی‌تواند با عملیات بد به شکلی قابل‌اطمینان اجرا شود.»**
در حالی که برخی جنبه‌های عملیات می‌توانند و باید خودکار شوند، در نهایت این انسان‌ها هستند که باید ابتدا آن خودکارسازی را راه‌اندازی کرده و از صحت عملکرد آن اطمینان حاصل کنند.

تیم‌های عملیات برای روان نگه داشتن اجرای سامانه‌های نرم‌افزاری حیاتی هستند.
یک تیم عملیات خوب معمولاً مسئولیت کارهایی مانند موارد زیر (و بیشتر) را بر عهده دارد:

* پایش سلامت سامانه و بازگرداندن سریع سرویس در صورت بروز وضعیت نامطلوب؛
* ریشه‌یابی علل مشکلاتی مانند شکست‌های سامانه یا افت عملکرد؛
* به‌روز نگه داشتن نرم‌افزار و پلتفرم‌ها، از جمله اعمال وصله‌های امنیتی؛
* زیر نظر داشتن نحوه‌ی تأثیرگذاری سامانه‌های مختلف بر یکدیگر، به‌طوری‌که بتوان از تغییرات مشکل‌ساز قبل از آسیب‌زدن جلوگیری کرد؛
* پیش‌بینی مشکلات آینده و حل آن‌ها قبل از وقوع (مثلاً برنامه‌ریزی ظرفیت)؛
* برقراری رویه‌ها و ابزارهای مناسب برای استقرار، مدیریت پیکربندی و سایر وظایف؛
* انجام وظایف نگهداری پیچیده مانند انتقال برنامه از یک پلتفرم به پلتفرمی دیگر؛
* حفظ امنیت سامانه همزمان با تغییرات در پیکربندی؛
* تعریف فرآیندهایی که عملیات را قابل پیش‌بینی کنند و محیط تولید را پایدار نگه دارند؛
* حفظ دانش سازمان درباره‌ی سامانه حتی با آمد و رفت افراد مختلف.

**قابلیت عملیات خوب یعنی آسان کردن وظایف روزمره، به‌طوری‌که تیم عملیات بتواند تمرکز خود را بر فعالیت‌های ارزشمندتر بگذارد.**
سیستم‌های داده می‌توانند با انجام کارهای مختلفی وظایف روزمره را ساده کنند، از جمله:

* فراهم کردن دید به رفتار زمان اجرای سامانه و اجزای داخلی آن با پایش (مانیتورینگ) مناسب؛
* پشتیبانی خوب از خودکارسازی و ادغام با ابزارهای استاندارد؛
* پرهیز از وابستگی به ماشین‌های منفرد (به‌طوری‌که ماشین‌ها را بتوان برای نگهداری از مدار خارج کرد در حالی که کل سامانه بدون وقفه به کار ادامه دهد)؛
* ارائه‌ی مستندات خوب و مدل عملیاتی قابل‌فهم («اگر کار X را انجام دهم، Y رخ می‌دهد»)؛
* داشتن رفتارهای پیش‌فرض مناسب، در عین حال فراهم کردن امکان تغییر پیش‌فرض‌ها برای مدیران سیستم در صورت نیاز؛
* خودترمیمی در صورت مناسب بودن، در عین حال دادن کنترل دستی به مدیران برای تغییر وضعیت سامانه در صورت نیاز؛
* رفتار قابل پیش‌بینی و کاهش غافلگیری‌ها.

---

## سادگی: مدیریت پیچیدگی (Simplicity: Managing Complexity)

پروژه‌های نرم‌افزاری کوچک می‌توانند کدی خوشایند، ساده و گویا داشته باشند،
اما هر چه پروژه‌ها بزرگ‌تر می‌شوند، اغلب بسیار پیچیده و دشوار برای درک می‌شوند.
این پیچیدگی سرعت همه‌ی افرادی را که باید روی سامانه کار کنند کاهش می‌دهد و هزینه‌ی نگهداری را بیشتر می‌کند.
پروژه‌ای که در باتلاق پیچیدگی فرو رفته باشد گاهی به عنوان **«گلوله‌ی بزرگی از گل» (big ball of mud)** توصیف می‌شود.

علائم مختلفی برای پیچیدگی وجود دارد:
افزایش نمایی فضای وضعیت، وابستگی شدید ماژول‌ها به یکدیگر، درهم‌تنیدگی وابستگی‌ها، نام‌گذاری و اصطلاحات ناسازگار، هک‌هایی برای حل مشکلات عملکردی، حالت‌های خاص برای دور زدن مشکلات دیگر بخش‌ها و بسیاری موارد دیگر.
در این موضوع تاکنون مطالب بسیاری گفته شده است.

زمانی که پیچیدگی نگهداری را دشوار می‌کند، معمولاً بودجه‌ها و زمان‌بندی‌ها از کنترل خارج می‌شوند.
در نرم‌افزارهای پیچیده، احتمال بروز باگ در حین اعمال تغییرات نیز بیشتر است:
هر چه درک و تحلیل سامانه برای توسعه‌دهندگان دشوارتر باشد، احتمال نادیده گرفتن فرضیات پنهان، پیامدهای ناخواسته و تعاملات غیرمنتظره بیشتر می‌شود.
برعکس، **کاهش پیچیدگی به‌شدت قابلیت نگهداری نرم‌افزار را بهبود می‌دهد** و بنابراین سادگی باید یکی از اهداف کلیدی سامانه‌هایی باشد که می‌سازیم.

ساده کردن سامانه لزوماً به معنای کاهش قابلیت‌های آن نیست؛
بلکه می‌تواند به معنای حذف **پیچیدگی تصادفی (accidental complexity)** نیز باشد.
**Moseley و Marks** پیچیدگی تصادفی را اینگونه تعریف می‌کنند:
پیچیدگی‌ای که ذاتی مسأله‌ای که نرم‌افزار حل می‌کند (از دید کاربر) نیست، بلکه صرفاً از نحوه‌ی پیاده‌سازی ناشی می‌شود.

یکی از بهترین ابزارهایی که برای حذف پیچیدگی تصادفی در اختیار داریم، **انتزاع (abstraction)** است.
یک انتزاع خوب می‌تواند مقدار زیادی از جزئیات پیاده‌سازی را پشت نمایی تمیز و قابل فهم پنهان کند.
یک انتزاع خوب همچنین می‌تواند در دامنه‌ی وسیعی از کاربردهای مختلف به کار رود.
این **بازاستفاده** نه تنها کارآمدتر از پیاده‌سازی مجدد چیزهای مشابه در چندین نقطه است، بلکه به کیفیت بالاتر نرم‌افزار نیز منجر می‌شود، زیرا بهبود کیفیت در مؤلفه‌ی انتزاع‌شده به همه‌ی برنامه‌هایی که از آن استفاده می‌کنند، سود می‌رساند.

برای مثال:
زبان‌های برنامه‌نویسی سطح بالا انتزاع‌هایی هستند که کد ماشین، ثبات‌های CPU و فراخوانی‌های سیستم را پنهان می‌کنند.
SQL انتزاعی است که ساختمان‌های داده پیچیده روی دیسک و در حافظه، درخواست‌های همزمان دیگر مشتریان و ناسازگاری‌های پس از سقوط را پنهان می‌کند.
البته زمانی که با زبان سطح بالا برنامه می‌نویسیم، همچنان از کد ماشین استفاده می‌کنیم؛
فقط به طور مستقیم با آن سروکار نداریم، زیرا انتزاع زبان برنامه‌نویسی ما را از فکر کردن به آن بی‌نیاز می‌کند.

با این حال، **یافتن انتزاع‌های خوب بسیار دشوار است**.
در حوزه‌ی سیستم‌های توزیع‌شده، هرچند الگوریتم‌های خوبی وجود دارد،
اما کمتر روشن است که چگونه باید آن‌ها را در قالب انتزاع‌هایی ارائه کنیم که به ما کمک کنند پیچیدگی سامانه را در سطحی قابل مدیریت نگه داریم.

در سراسر این کتاب، همواره به دنبال انتزاع‌های خوبی خواهیم بود که بتوان بخش‌هایی از یک سامانه‌ی بزرگ را به مؤلفه‌های تعریف‌شده و قابل بازاستفاده تبدیل کرد.

---


## قابلیت تحول: آسان کردن تغییر (Evolvability: Making Change Easy)

به‌ندرت ممکن است که نیازمندی‌های سامانه‌ی شما برای همیشه بدون تغییر باقی بماند.
احتمال بسیار بیشتری وجود دارد که نیازمندی‌ها **دائماً در حال تغییر باشند**:
شما حقایق جدیدی یاد می‌گیرید، کاربردهای پیش‌بینی‌نشده ظاهر می‌شوند، اولویت‌های کسب‌وکار تغییر می‌کنند، کاربران ویژگی‌های جدید درخواست می‌کنند، پلتفرم‌های جدید جایگزین پلتفرم‌های قدیمی می‌شوند، الزامات قانونی یا مقررات تغییر می‌کند، رشد سامانه تغییرات معماری را اجبار می‌کند و غیره.

از نظر فرآیندهای سازمانی، الگوهای کاری **Agile** چارچوبی برای سازگاری با تغییر فراهم می‌کنند.
جامعه‌ی Agile همچنین ابزارها و الگوهای فنی‌ای برای توسعه‌ی نرم‌افزار در محیطی با تغییرات مکرر ارائه کرده است، مانند **توسعه مبتنی بر آزمون (TDD)** و **بازآرایی (Refactoring)**.

بیشتر بحث‌های مربوط به این تکنیک‌های Agile روی مقیاسی کوچک و محلی تمرکز دارند (مثلاً چند فایل کد منبع در داخل یک برنامه‌ی واحد).
در این کتاب، به دنبال روش‌هایی هستیم که چابکی را در **سطح یک سامانه‌ی داده‌ی بزرگ‌تر** افزایش دهیم —
شاید متشکل از چندین برنامه یا سرویس مختلف با ویژگی‌های گوناگون.
برای مثال: چگونه می‌توان معماری توییتر برای ایجاد جدول زمانی خانه را از **رویکرد ۱ به رویکرد ۲** بازآرایی (refactor) کرد؟ (در بخش «توصیف بار» شرح داده شد.)

میزان سهولت در تغییر یک سامانه‌ی داده و تطبیق آن با نیازهای در حال تغییر، به شکل نزدیکی با **سادگی و انتزاع‌های آن** مرتبط است:
سامانه‌های ساده و قابل‌فهم معمولاً راحت‌تر از سامانه‌های پیچیده تغییر می‌کنند.
اما چون این ایده بسیار مهم است، برای اشاره به چابکی در سطح سامانه‌ی داده از واژه‌ی متفاوتی استفاده می‌کنیم: **قابلیت تحول (evolvability)**.

